- [Site Reliability Engineering](#site-reliability-engineering)
  * [Part I Introduction](#part-i-introduction)
    + [Chapter 1 Introduction](#chapter-1-introduction)
    + [Chapter 2 The Production Environment at Google, from the Viewpoint of an SRE](#chapter-2-the-production-environment-at-google-from-the-viewpoint-of-an-sre)
    + [Chapter 3 Embracing Risk](#chapter-3-embracing-risk)
  * [Part II Principles](#part-ii-principles)
    + [Chapter 4 Service Level Objectives](#chapter-4-service-level-objectives)
    + [Chapter 5 Eliminating Toil](#chapter-5-eliminating-toil)
    + [Chapter 6 Monitoring Distributed Systems](#chapter-6-monitoring-distributed-systems)
    + [Chapter 7 The Evolution of Automation at Google](#chapter-7-the-evolution-of-automation-at-google)
    + [Chapter 8 Release Engineering](#chapter-8-release-engineering)
    + [Chapter 9 Simplicity](#chapter-9-simplicity)
  * [Part III - Practices](#part-iii---practices)
    + [Chapter 10 Practical Alerting](#chapter-10-practical-alerting)
    + [Chapter 11 Being On-Call](#chapter-11-being-on-call)
    + [Chapter 12 Effective Troubleshooting](#chapter-12-effective-troubleshooting)
    + [Chapter 13 Emergency Response](#chapter-13-emergency-response)
    + [Chapter 14 Managing Incidents](#chapter-14-managing-incidents)
    + [Chapter 15 Postmortem Culture: Learning from Failure](#chapter-15-postmortem-culture-learning-from-failure)
    + [Chapter 16 Tracking Outages](#chapter-16-tracking-outages)
    + [Chapter 17 Testing for Reliability](#chapter-17-testing-for-reliability)
    + [Chapter 18 Software Engineering in SRE](#chapter-18-software-engineering-in-sre)
    + [Chapter 19 Load Balancing at the Frontend](#chapter-19-load-balancing-at-the-frontend)
    + [Chapter 20 Load Balancing in the Datacenter](#chapter-20-load-balancing-in-the-datacenter)
    + [Chapter 21 Handling Overload](#chapter-21-handling-overload)
    + [Chapter 22 Addressing Cascading Failures](#chapter-22-addressing-cascading-failures)
    + [Chapter 23 Managing Critical State: Distributed Consensus for Reliability](#chapter-23-managing-critical-state-distributed-consensus-for-reliability)
    + [Chapter 24 Distributed Periodic Scheduling with Cron](#chapter-24-distributed-periodic-scheduling-with-cron)
    + [Chapter 25 Data Processing Pipelines](#chapter-25-data-processing-pipelines)
    + [Chapter 26 Data Integrity: What You Read Is What You Wrote](#chapter-26-data-integrity-what-you-read-is-what-you-wrote)
    + [Chapter 27 Reliable Product Launches at Scale](#chapter-27-reliable-product-launches-at-scale)
  * [Part IV - Management](#part-iv---management)
    + [Chapter 28 Accelerating SREs to On-Call and Beyond](#chapter-28-accelerating-sres-to-on-call-and-beyond)
    + [Chapter 29 Dealing with Interrupts](#chapter-29-dealing-with-interrupts)
    + [Chapter 30 Embedding an SRE to Recover from Operational Overload](#chapter-30-embedding-an-sre-to-recover-from-operational-overload)
    + [Chapter 31 Communication and Collaboration in SRE](#chapter-31-communication-and-collaboration-in-sre)
    + [Chapter 32 The Evolving SRE Engagement Model](#chapter-32-the-evolving-sre-engagement-model)
  * [Part V - Conclusions](#part-v---conclusions)
    + [Chapter 33 Lessons Learned from Other Industries](#chapter-33-lessons-learned-from-other-industries)
    + [Chapter 34 Conclusion](#chapter-34-conclusion)
___

# Site Reliability Engineering

## Part I Introduction

### Chapter 1 Introduction

-[text](https://sre.google/sre-book/introduction/)
- historically, companies have employed systems administrators to run complex
  computing system
  * product developers and sysadmins are divided into discrete teams
    + development
    + operations
  * advantages
    + integration companies are available to help run those assembled systems,
      so a novice sysadmin team does not have to reinvent the wheel and design
      a system from scratch
  * disadvantages
    + direct costs
      + running a service with a team that relies on manual intervention for
        both change management and event handling becomes expensive as the
        service and/or traffic to the service grows, because the size of the
        team necessarily scales with the load generated by the system
    + indirect costs
      + development and operations team are quite different in background, skill
        set and incentives; they use different vocabulary to describe
        situations; they carry different assumptions about both risk and
        possibilities for technical solutions; they have different assumptions
        about the target level of product stability; they split between the
        groups can easily become one of not just incentives, but also
        communication, goals, and eventually, trust and respect; this outcome is
        a pathology

### Chapter 2 The Production Environment at Google, from the Viewpoint of an SRE

- [text](https://sre.google/sre-book/production-environment/)
- a single shared repository
  * engineers encounter a problem in a componment (or service) outside their
    project, they can fix the problem, send a pull request to the owner for
    merge the pull request to production

## Part II Principles

- [text](https://sre.google/sre-book/part-II-principles/)
- the industry commonly lumps disparate concepts under the general banner of
  SLA, a tendency that makes it harder to think about these concepts clearly;
  SLO attempts to disentangle indicators from objectives from agreements

### Chapter 3 Embracing Risk

- [text](https://sre.google/sre-book/embracing-risk/)
- extreme reliability comes at a cost: maximising stability limits how fast new
  features can be developed and how quickly products can be delivered to users,
  and dramatically increases their cost, which in turn reduces the number of
  features a team can afford to offer
- examples of risk can be taken
  * a user on a 99% reliable smartphone cannot tell the difference between
    99.99% and 99.999% service reliability
- site reliability engineering seeks to balance the risk of unavailability with
  the goals of rapid innovation and efficient service operations, so that users’
  overall happiness—with features, service, and performance—is optimized
- costs of reducing too much risk
  * cost of redundant compute resources
  * opportunity cost
    + the cost borne by an organization when it allocates engineering resources
      to build systems or features that diminish risk instead of features that
      are directly visible to or usable by end users
- drawbacks of using time-based availability
  * since platforms these days are seldom made of only one service, time-based
    availability may not be meaningful in case of all services but one is down;
    this "partially" up nature make time-based availability less useful
- aggregated availability
  * a yield-based metric calculated over a rolling window
  * quantifying unplanned downtime as a request success rate also makes this
    availability metric more amenable for use in systems that do not typically
    serve end users directly
    + examples
      + using a request success rate defined in terms of records successfully
        and unsuccessfully processed, we can calculate a useful availability
        metric despite the fact that the batch system does not run constantly
  * quarterly availability targets for a service can be set and it can be used
    to track performance against those targets on a weekly, or even daily, basis
- risk tolerance of services is typically built directly into the basic product
  or service definition
- to identify the risk tolerance of consumer services
  * target level of availability
    + an external quarterly target can be set and back this target with
      a stronger internal availability target
  * types of failures
    + examples
      + a constant low rate of failures
      + an occasional full-site outage
    + planned downtime
    + unplanned downtime
  * cost
  * other service metrics
    + examples
      + latency
- motivation for error budgets
  * different incentives from teams
    + product development
      + performance is largely evaluated on product velocity, which creates an
        incentive to push new code as quickly as possible
    + SRE
      + performance is evaluated based upon reliability of a service, which
        implies an incentive to push back against a high rate of change
- factors to consider in determining error budgets
  * software fault tolerance
    + how hardened do we make the software to unexpected events?
  * testing
    + not enough testing and you have embarrassing outages, privacy data leaks,
      or a number of other press-worthy events; testing too much may get into
      a problem of moving too slow in terms of product development
  * push frequency
  * canary duration and size
    + it is a best practice to test a new release on some small subset of
      a typical workload, a practice often called canarying. How long do we
      wait, and how big is the canary?
  * usually, preexisting teams have worked out some kind of informal balance
    between them as to where the risk/effort boundary lies; unfortunately, one
    can rarely prove that this balance is optimal, rather than just a function
    of the negotiating skills of the engineers involved; nor should such
    decisions be driven by politics, fear, or hope
- forming an error budget
  * application development and SRE team jointly define a quarterly error budget
    based on the SLO of the service
  * this metric removes the politics from negotiations between SREs and
    application developers when deciding how much risk to allow
  * use caess
    + as long as there is error budget remaining, new releases can be pushed
    + slowing down releases or rolling releases back when SLO-violation error
      budget is close to being used up
    + if product development wants to skimp on testing or increase push velocity
      and SRE is resistant, the error budget guides the decision
      + when the budget is large, the product developers can take more risks
      + when the budget is nearly drained, the product developers themselves
        will push for more testing or slower push velocity, as they do not want
        to risk using up the budget and stall their launch
      + in effect, the product development team becomes self-policing
    + if a network outage or datacenter failure reduces the measured SLO
      + the number of new pushes may be reduced for the remainder of the quarter
      + the entire team supports this reduction because everyone shares the
        responsibility for uptime
      + this make sense because the budget reflects what end-user is
        experiencing and further risk can be taken has been reduced due to the
        outage

### Chapter 4 Service Level Objectives

-[text](https://sre.google/sre-book/service-level-objectives/)
- SLI
  * a carefully defined quantitative measure of some aspect of the level of
    service that is provided
  * examples
    + request latency
    + error rate
    + throughput as request per second
    + availability as the fraction of the time that a service is usable
      + yield
        + the fraction of well-formed requests that succeed
      + often referred to as number of 9s
  * proxy measures is used as direct measurements are hard to obtain or
    interpret
    + examples
      + server side latency as a proxy for client side latency
- SLO
  * a target value or range of values for a service level that is measured by an
    SLI
  * examples
    + SLI ≤ target
    + lower bound ≤ SLI ≤ upper bound
  * choosing and publishing SLOs to users sets expectations about how a service
    will perform
    + this strategy can reduce unfounded complaints to service owners about, for
      example, the service being slow
- SLA
  * an overloaded term and it has taken on a number of meanings depending on
    context
  * an explicit or implicit contract with your users that includes consequences
    of meeting (or missing) the SLOs they contain
  * the consequences are most easily recognized when they are financial but they
    can take other forms
  * an easy way to tell the difference between an SLO and an SLA is to ask "what
    happens if the SLOs aren’t met?"
    + if there is no explicit consequence, then you are almost certainly looking
    + at an SLO
  * SRE does not typically get involved in constructing SLAs, because SLAs are
    closely tied to business and product decisions
  * whether or not a particular service has an SLA, it is valuable to define
    SLIs and SLOs and use them to manage the service
- relavant SLIs
  * not every metric should be used as an SLI
  * choosing too many indicators makes it hard to pay the right level of
    attention to the indicators that matter, while choosing too few may leave
    significant behaviors of your system unexamined
  * an understanding from user's perspective will inform the judicious selection
    of a few indicators
  * examples
    + user-facing serving systems
      + availability, latency, throughput
    + big data systems (or business intelligence systems)
      + throughput, end-to-end latency (how long does it take the data from
        ingestion to completion)
    + all systems
      + correctness
- percentiles
  * a high-order percentile (such as 99th) shows a plausible worst-case
    experience for a user
  * median (50th) emphasizes the typical experience
- statistics
  * it should not be assumed without verifying that metrics collected are
    normally distributed

### Chapter 5 Eliminating Toil

-[text](https://sre.google/sre-book/eliminating-toil/)

### Chapter 6 Monitoring Distributed Systems

-[text](https://sre.google/sre-book/monitoring-distributed-systems/)

### Chapter 7 The Evolution of Automation at Google

-[text](https://sre.google/sre-book/automation-at-google/)

### Chapter 8 Release Engineering

-[text](https://sre.google/sre-book/release-engineering/)

### Chapter 9 Simplicity

-[text](https://sre.google/sre-book/simplicity/)

## Part III - Practices

- [text](https://sre.google/sre-book/part-III-practices/)

### Chapter 10 Practical Alerting

-[text](https://sre.google/sre-book/practical-alerting/)

### Chapter 11 Being On-Call

-[text](https://sre.google/sre-book/being-on-call/)

### Chapter 12 Effective Troubleshooting

-[text](https://sre.google/sre-book/effective-troubleshooting/)

### Chapter 13 Emergency Response

-[text](https://sre.google/sre-book/emergency-response/)

### Chapter 14 Managing Incidents

-[text](https://sre.google/sre-book/managing-incidents/)

### Chapter 15 Postmortem Culture: Learning from Failure


-[text](https://sre.google/sre-book/postmortem-culture/)

### Chapter 16 Tracking Outages

-[text](https://sre.google/sre-book/tracking-outages/)

### Chapter 17 Testing for Reliability

-[text](https://sre.google/sre-book/testing-reliability/)

### Chapter 18 Software Engineering in SRE

-[text](https://sre.google/sre-book/software-engineering-in-sre/)

### Chapter 19 Load Balancing at the Frontend

-[text](https://sre.google/sre-book/load-balancing-frontend/)

### Chapter 20 Load Balancing in the Datacenter

-[text](https://sre.google/sre-book/load-balancing-datacenter/)

### Chapter 21 Handling Overload

-[text](https://sre.google/sre-book/handling-overload/)

### Chapter 22 Addressing Cascading Failures

-[text](https://sre.google/sre-book/addressing-cascading-failures/)

### Chapter 23 Managing Critical State: Distributed Consensus for Reliability

-[text](https://sre.google/sre-book/managing-critical-state/)

### Chapter 24 Distributed Periodic Scheduling with Cron

-[text](https://sre.google/sre-book/distributed-periodic-scheduling/)

### Chapter 25 Data Processing Pipelines

- [text](https://sre.google/sre-book/data-processing-pipelines/)

### Chapter 26 Data Integrity: What You Read Is What You Wrote

- [text](https://sre.google/sre-book/data-integrity/)

### Chapter 27 Reliable Product Launches at Scale

- [text](https://sre.google/sre-book/reliable-product-launches/)

## Part IV - Management

### Chapter 28 Accelerating SREs to On-Call and Beyond

- [text](https://sre.google/sre-book/accelerating-sre-on-call/)

### Chapter 29 Dealing with Interrupts

- [text](https://sre.google/sre-book/dealing-with-interrupts/)

### Chapter 30 Embedding an SRE to Recover from Operational Overload

- [text](https://sre.google/sre-book/operational-overload/)

### Chapter 31 Communication and Collaboration in SRE

- [text](https://sre.google/sre-book/communication-and-collaboration/)

### Chapter 32 The Evolving SRE Engagement Model

- [text](https://sre.google/sre-book/evolving-sre-engagement-model/)

## Part V - Conclusions

### Chapter 33 Lessons Learned from Other Industries

- [text](https://sre.google/sre-book/lessons-learned/)

### Chapter 34 Conclusion

- [text](https://sre.google/sre-book/conclusion/)

